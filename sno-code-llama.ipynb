{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a277a4a9-1f52-44bf-9039-8b1a2221c005",
   "metadata": {},
   "source": [
    "Download a pretrained codellama model. This is finetuned for python [CodeLlama-7B-Instruct-GGUF](https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70fe40ce-0eb3-435c-8b29-33731a67244c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-03 22:20:34--  https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q8_0.gguf?download=true\n",
      "Resolving huggingface.co (huggingface.co)... 3.160.5.76, 3.160.5.109, 3.160.5.25, ...\n",
      "Connecting to huggingface.co (huggingface.co)|3.160.5.76|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.huggingface.co/repos/b7/f6/b7f68e1c7abee7ca052604f565465a073f450bb16d60428836f9cca7677ddeb1/2126a5b9e8576ebea8889792ec5e459423935daae17ac0ffdfbedb39d222a20e?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27codellama-7b-instruct.Q8_0.gguf%3B+filename%3D%22codellama-7b-instruct.Q8_0.gguf%22%3B&Expires=1715034035&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNTAzNDAzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iNy9mNi9iN2Y2OGUxYzdhYmVlN2NhMDUyNjA0ZjU2NTQ2NWEwNzNmNDUwYmIxNmQ2MDQyODgzNmY5Y2NhNzY3N2RkZWIxLzIxMjZhNWI5ZTg1NzZlYmVhODg4OTc5MmVjNWU0NTk0MjM5MzVkYWFlMTdhYzBmZmRmYmVkYjM5ZDIyMmEyMGU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=Y9Ds18-COmUpFSmmccNSg4vjFJM38XPVH1veI0DwYYDLZl64jwELh9psWLArgWpn5qaoJpSXfxUKFWqggwsiVYgzxTQdX35L7iFaAbUmyVGIwld7umqKPcPE7Qibc8-lgkwMRKFZoWDT%7Eo8H1x1deyIqhIGafJi7EdMOl9MADVbA3hdPoVusVJXThEKFLLhgTmhCT%7EEJnxUdOKO%7EBhiuOTJzhfS5nQzpSV81kE9tuHHbf%7ELe3uXX2qhR4M82GZViD%7EP7lgBA7oPC8iiM3fPyM9S%7EGwGYGtA15QEbzj6xrx5kt0%7E4oCB-nYu%7EXBDX%7EgM%7EeTa32Ademxn7xXBqrYw9Jg__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
      "--2024-05-03 22:20:35--  https://cdn-lfs.huggingface.co/repos/b7/f6/b7f68e1c7abee7ca052604f565465a073f450bb16d60428836f9cca7677ddeb1/2126a5b9e8576ebea8889792ec5e459423935daae17ac0ffdfbedb39d222a20e?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27codellama-7b-instruct.Q8_0.gguf%3B+filename%3D%22codellama-7b-instruct.Q8_0.gguf%22%3B&Expires=1715034035&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNTAzNDAzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iNy9mNi9iN2Y2OGUxYzdhYmVlN2NhMDUyNjA0ZjU2NTQ2NWEwNzNmNDUwYmIxNmQ2MDQyODgzNmY5Y2NhNzY3N2RkZWIxLzIxMjZhNWI5ZTg1NzZlYmVhODg4OTc5MmVjNWU0NTk0MjM5MzVkYWFlMTdhYzBmZmRmYmVkYjM5ZDIyMmEyMGU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=Y9Ds18-COmUpFSmmccNSg4vjFJM38XPVH1veI0DwYYDLZl64jwELh9psWLArgWpn5qaoJpSXfxUKFWqggwsiVYgzxTQdX35L7iFaAbUmyVGIwld7umqKPcPE7Qibc8-lgkwMRKFZoWDT%7Eo8H1x1deyIqhIGafJi7EdMOl9MADVbA3hdPoVusVJXThEKFLLhgTmhCT%7EEJnxUdOKO%7EBhiuOTJzhfS5nQzpSV81kE9tuHHbf%7ELe3uXX2qhR4M82GZViD%7EP7lgBA7oPC8iiM3fPyM9S%7EGwGYGtA15QEbzj6xrx5kt0%7E4oCB-nYu%7EXBDX%7EgM%7EeTa32Ademxn7xXBqrYw9Jg__&Key-Pair-Id=KVTP0A1DKRTAX\n",
      "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 108.156.184.64, 108.156.184.106, 108.156.184.7, ...\n",
      "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|108.156.184.64|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7161229504 (6.7G) [binary/octet-stream]\n",
      "Saving to: ‘codellama-7b.Q8_0.gguf’\n",
      "\n",
      "codellama-7b.Q8_0.g 100%[===================>]   6.67G   144MB/s    in 30s     \n",
      "\n",
      "2024-05-03 22:21:04 (230 MB/s) - ‘codellama-7b.Q8_0.gguf’ saved [7161229504/7161229504]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O codellama-7b-instruct.Q8_0.gguf https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q8_0.gguf?download=true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d90de0d-32e3-47e7-b384-9b89a80e820d",
   "metadata": {
    "tags": []
   },
   "source": [
    "We are going to upload this into our s3 bucket for serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2151271-5b2a-4eb7-977d-b42d576998cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting awscli\n",
      "  Downloading awscli-1.32.98-py3-none-any.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: colorama<0.4.7,>=0.2.5 in /opt/app-root/lib/python3.9/site-packages (from awscli) (0.4.6)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0\n",
      "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m196.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docutils<0.17,>=0.10\n",
      "  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.2/548.2 kB\u001b[0m \u001b[31m223.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<4.8,>=3.1.2\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: PyYAML<6.1,>=3.10 in /opt/app-root/lib/python3.9/site-packages (from awscli) (6.0.1)\n",
      "Collecting botocore==1.34.98\n",
      "  Downloading botocore-1.34.98-py3-none-any.whl (12.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m133.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/app-root/lib/python3.9/site-packages (from botocore==1.34.98->awscli) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/app-root/lib/python3.9/site-packages (from botocore==1.34.98->awscli) (2.9.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/app-root/lib/python3.9/site-packages (from botocore==1.34.98->awscli) (1.26.18)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/app-root/lib/python3.9/site-packages (from rsa<4.8,>=3.1.2->awscli) (0.5.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.34.98->awscli) (1.16.0)\n",
      "Installing collected packages: rsa, docutils, botocore, s3transfer, awscli\n",
      "  Attempting uninstall: rsa\n",
      "    Found existing installation: rsa 4.9\n",
      "    Uninstalling rsa-4.9:\n",
      "      Successfully uninstalled rsa-4.9\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.31.85\n",
      "    Uninstalling botocore-1.31.85:\n",
      "      Successfully uninstalled botocore-1.31.85\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.7.0\n",
      "    Uninstalling s3transfer-0.7.0:\n",
      "      Successfully uninstalled s3transfer-0.7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "boto3 1.28.85 requires botocore<1.32.0,>=1.31.85, but you have botocore 1.34.98 which is incompatible.\n",
      "boto3 1.28.85 requires s3transfer<0.8.0,>=0.7.0, but you have s3transfer 0.10.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed awscli-1.32.98 botocore-1.34.98 docutils-0.16 rsa-4.7.2 s3transfer-0.10.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install awscli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26f87d2-0c67-4972-8ad3-fc5ceafdb2b2",
   "metadata": {},
   "source": [
    "Ensure you have NOOBAA_SECRET_KEY, NOOBAA_ACCESS_KEY, S3_ENPOINT exported in your notebook environment before uploading to s3.\n",
    "e.g.\n",
    "S3_ENDPOINT = https://s3-openshift-storage.apps.sno.sandbox.opentlc.com:443"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8620070d-b91b-4f2c-8078-dacf7a1ba547",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./codellama-7b-instruct.Q8_0.gguf to s3://models/codellama-7b-instruct.Q8_0.gguf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.system(\"\"\"\n",
    "    alias s3='AWS_ACCESS_KEY_ID=$NOOBAA_ACCESS_KEY AWS_SECRET_ACCESS_KEY=$NOOBAA_SECRET_KEY aws --endpoint $S3_ENDPOINT s3'\n",
    "    if s3 ls \"s3://models\" 2>&1 | grep -q 'NoSuchBucket'; then\n",
    "      s3 mb s3://models\n",
    "    fi\n",
    "    s3 cp codellama-7b-instruct.Q8_0.gguf s3://models/codellama-7b-instruct.Q8_0.gguf\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32b05fd-4bd7-466f-bc2b-5c277afc9b90",
   "metadata": {},
   "source": [
    "Let's try the model out locally first, see what it can do! Make sure transformers library installed - we're using the gpu enabled cuda version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec0f7358-6d5c-4250-9688-bf9afc8573aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ctransformers[cuda] in /opt/app-root/lib/python3.9/site-packages (0.2.27)\n",
      "Requirement already satisfied: huggingface-hub in /opt/app-root/lib/python3.9/site-packages (from ctransformers[cuda]) (0.23.0)\n",
      "Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /opt/app-root/lib/python3.9/site-packages (from ctransformers[cuda]) (9.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12 in /opt/app-root/lib/python3.9/site-packages (from ctransformers[cuda]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cublas-cu12 in /opt/app-root/lib/python3.9/site-packages (from ctransformers[cuda]) (12.4.5.8)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub->ctransformers[cuda]) (23.2)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub->ctransformers[cuda]) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub->ctransformers[cuda]) (4.10.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub->ctransformers[cuda]) (2024.2.0)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub->ctransformers[cuda]) (3.13.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub->ctransformers[cuda]) (4.66.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub->ctransformers[cuda]) (6.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface-hub->ctransformers[cuda]) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface-hub->ctransformers[cuda]) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface-hub->ctransformers[cuda]) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface-hub->ctransformers[cuda]) (1.26.18)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ctransformers[cuda]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b2e76-95a2-42bb-b936-751e26cd9257",
   "metadata": {},
   "source": [
    "Load our model from local disk. Ask it to generate some basic python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2009d637-2e29-4df6-991c-9a32faa5ce66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "'''\n",
      "from jinja2 import Template\n",
      "\n",
      "template = \"\"\"\\\n",
      "# {{ filename }} - Example # {{ i }}\n",
      "print(\"Hello, World!\")\n",
      "\"\"\"\n",
      "\n",
      "i = 1\n",
      "while i < 3:\n",
      "    with open(f'{i}.py', 'w') as file:\n",
      "        file.write(Template(template).render(filename=i))\n",
      "    i += 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "llm = AutoModelForCausalLM.from_pretrained(\"./codellama-7b-instruct.Q8_0.gguf\", local_files_only=True, gpu_layers=-1)\n",
    "\n",
    "print(llm(\"generate python code to print Hello World\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14b627e-6bb4-45b3-96d6-3fceff5007cc",
   "metadata": {},
   "source": [
    "Run the generated code in our notebook ... it runs ! ship it !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a7bcfb5-aee6-48ce-95b7-8326b9e985e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "\n",
    "template = \"\"\"\\\n",
    "# {{ filename }} - Example # {{ i }}\n",
    "print(\"Hello, World!\")\n",
    "\"\"\"\n",
    "\n",
    "i = 1\n",
    "while i < 3:\n",
    "    with open(f'{i}.py', 'w') as file:\n",
    "        file.write(Template(template).render(filename=i))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59e14316-3575-4c2c-805b-a66193060cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "!python 1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54724ad2-3e24-469e-87d9-965c173844bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
