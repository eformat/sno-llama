{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ac1b9c-8f8e-4de1-8a82-f55e8933b8cb",
   "metadata": {},
   "source": [
    "## Instruct Lab demo\n",
    "\n",
    "Let's try out the demo for instruct lab using our sno-llama environment - [you can see the youtube video here](https://www.youtube.com/watch?v=pgK-70iLz_o).\n",
    "\n",
    "First we need to build an instructlab notebook image.\n",
    "\n",
    "Take a look at the [REDAME.md](instructlab/README.md), run the instructions and build a custom notebook image for this environment.\n",
    "\n",
    "Tag the image so we can use it to launch an ilab notebook.\n",
    "\n",
    "We can check that ilab is deployed using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4b786a1-cae2-458b-9462-09b19f228ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: ilab [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "  CLI for interacting with InstructLab.\n",
      "\n",
      "  If this is your first time running InstructLab, it's best to start with\n",
      "  `ilab init` to create the environment.\n",
      "\n",
      "Options:\n",
      "  --config PATH  Path to a configuration file.  [default: config.yaml]\n",
      "  --version      Show the version and exit.\n",
      "  --help         Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  chat      Run a chat using the modified model\n",
      "  check     (Deprecated) Check that taxonomy is valid\n",
      "  convert   Converts model to GGUF\n",
      "  diff      Lists taxonomy files that have changed since <taxonomy-base>...\n",
      "  download  Download the model(s) to train\n",
      "  generate  Generates synthetic data to enhance your example data\n",
      "  init      Initializes environment for InstructLab\n",
      "  list      (Deprecated) Lists taxonomy files that have changed since\n",
      "            <taxonomy-base>.\n",
      "  serve     Start a local server\n",
      "  test      Runs basic test to ensure model correctness\n",
      "  train     Takes synthetic data generated locally with `ilab generate`...\n"
     ]
    }
   ],
   "source": [
    "!ilab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d827e1-c0aa-4ad2-84c2-e785c922e4bf",
   "metadata": {},
   "source": [
    "Create a directory called instructlab. We will use this to train a model using instructlab. We can do most of this work on the terminal. You may find it easier to just `oc rsh jupyter-nb-admin-0` into your running notebook and run the instructions from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b8eef46-0c4f-4abb-a88a-b34b1744de8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p $HOME/instructlab/models && cd $HOME/instructlab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf18112-86f9-4370-a8ee-0153c5910738",
   "metadata": {},
   "source": [
    "Now we need to initialize instructlab. Ask it to initize a blank taxonomy directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586e30b1-7a3b-4b10-a274-ab8b2945dcc0",
   "metadata": {},
   "source": [
    "```bash\n",
    "(app-root) ilab init\n",
    "Welcome to InstructLab CLI. This guide will help you to setup your environment.\n",
    "Please provide the following values to initiate the environment [press Enter for defaults]:\n",
    "Path to taxonomy repo [taxonomy]: \n",
    "`taxonomy` seems to not exist or is empty. Should I clone https://github.com/instructlab/taxonomy.git for you? [y/N]: y\n",
    "Cloning https://github.com/instructlab/taxonomy.git...\n",
    "Generating `config.yaml` in the current directory...\n",
    "Initialization completed successfully, you're ready to start using `ilab`. Enjoy!\n",
    "(app-root) ls\n",
    "config.yaml models taxonomy\n",
    "(app-root)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220a8694-18cf-421f-a73a-80ca63ca5b74",
   "metadata": {},
   "source": [
    "The default configuration uses a `merlinite-7b-lab-Q4_K_M` based model - lets swap it out for our granite model we used in the sno-granite notebook demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4c0791a-7bb2-4a79-ace1-ceef4fce1b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-12 01:50:57--  https://huggingface.co/instructlab/granite-7b-lab-GGUF/resolve/main/granite-7b-lab-Q4_K_M.gguf?download=true\n",
      "Resolving huggingface.co (huggingface.co)... 3.160.5.109, 3.160.5.102, 3.160.5.25, ...\n",
      "Connecting to huggingface.co (huggingface.co)|3.160.5.109|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs-us-1.huggingface.co/repos/b4/aa/b4aa486646dd15418b4143b2bd1fe324e82dcd41f9d35edd4c178194d9b57df9/6adeaad8c048b35ea54562c55e454cc32c63118a32c7b8152cf706b290611487?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27granite-7b-lab-Q4_K_M.gguf%3B+filename%3D%22granite-7b-lab-Q4_K_M.gguf%22%3B&Expires=1715737858&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNTczNzg1OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2I0L2FhL2I0YWE0ODY2NDZkZDE1NDE4YjQxNDNiMmJkMWZlMzI0ZTgyZGNkNDFmOWQzNWVkZDRjMTc4MTk0ZDliNTdkZjkvNmFkZWFhZDhjMDQ4YjM1ZWE1NDU2MmM1NWU0NTRjYzMyYzYzMTE4YTMyYzdiODE1MmNmNzA2YjI5MDYxMTQ4Nz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=UyEg%7EwP1%7EvF56C29EDRqzfqUh%7ETLl6RK9d%7Elw78K4kTrFDLC0TF7Z1LUjrldIV%7EuaIoBFiXS5Mmcaw3XK4RMq1zChf-OieSVRoSvxvFveuhHGz94EMCpJWGpQAq%7E5HcVKit7L-CZB1oclNeBwCit5trfNCExBRpqqRrv8zQ1wyXnX8QO9Vulqo-FYKipaV60bwKESwHFtKwuHoFQ4W66G6UNbNn19nSlrK-QkyX3Pfsfm1ZtCZm4TB%7E5LakVvIuJFlNJB96LHRvXNqOYKDsMOIMZnbOiG0jfNmB3EG-OIm91HhD%7EEGhnq7R-5zf44sLMGZCn1rEWet1smZxT6FO4Rg__&Key-Pair-Id=KCD77M1F0VK2B [following]\n",
      "--2024-05-12 01:50:58--  https://cdn-lfs-us-1.huggingface.co/repos/b4/aa/b4aa486646dd15418b4143b2bd1fe324e82dcd41f9d35edd4c178194d9b57df9/6adeaad8c048b35ea54562c55e454cc32c63118a32c7b8152cf706b290611487?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27granite-7b-lab-Q4_K_M.gguf%3B+filename%3D%22granite-7b-lab-Q4_K_M.gguf%22%3B&Expires=1715737858&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNTczNzg1OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2I0L2FhL2I0YWE0ODY2NDZkZDE1NDE4YjQxNDNiMmJkMWZlMzI0ZTgyZGNkNDFmOWQzNWVkZDRjMTc4MTk0ZDliNTdkZjkvNmFkZWFhZDhjMDQ4YjM1ZWE1NDU2MmM1NWU0NTRjYzMyYzYzMTE4YTMyYzdiODE1MmNmNzA2YjI5MDYxMTQ4Nz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=UyEg%7EwP1%7EvF56C29EDRqzfqUh%7ETLl6RK9d%7Elw78K4kTrFDLC0TF7Z1LUjrldIV%7EuaIoBFiXS5Mmcaw3XK4RMq1zChf-OieSVRoSvxvFveuhHGz94EMCpJWGpQAq%7E5HcVKit7L-CZB1oclNeBwCit5trfNCExBRpqqRrv8zQ1wyXnX8QO9Vulqo-FYKipaV60bwKESwHFtKwuHoFQ4W66G6UNbNn19nSlrK-QkyX3Pfsfm1ZtCZm4TB%7E5LakVvIuJFlNJB96LHRvXNqOYKDsMOIMZnbOiG0jfNmB3EG-OIm91HhD%7EEGhnq7R-5zf44sLMGZCn1rEWet1smZxT6FO4Rg__&Key-Pair-Id=KCD77M1F0VK2B\n",
      "Resolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 108.156.184.127, 108.156.184.107, 108.156.184.98, ...\n",
      "Connecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|108.156.184.127|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4081050336 (3.8G) [application/octet-stream]\n",
      "Saving to: ‘/opt/app-root/src/instructlab/models/granite-7b-lab-Q4_K_M.gguf’\n",
      "\n",
      "/opt/app-root/src/i 100%[===================>]   3.80G   330MB/s    in 11s     \n",
      "\n",
      "2024-05-12 01:51:09 (354 MB/s) - ‘/opt/app-root/src/instructlab/models/granite-7b-lab-Q4_K_M.gguf’ saved [4081050336/4081050336]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O $HOME/instructlab/models/granite-7b-lab-Q4_K_M.gguf https://huggingface.co/instructlab/granite-7b-lab-GGUF/resolve/main/granite-7b-lab-Q4_K_M.gguf?download=true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d13b748-62db-4100-a172-93dc457fc177",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now modify the `config.yaml` to point to our granite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c538da7b-6da6-4fd9-ada5-784a689cb024",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat <<'EOF' > $HOME/instructlab/config.yaml\n",
    "chat:\n",
    "  context: default\n",
    "  greedy_mode: false\n",
    "  logs_dir: data/chatlogs\n",
    "  model: granite-7b-lab-Q4_K_M\n",
    "  session: null\n",
    "  vi_mode: false\n",
    "  visible_overflow: true\n",
    "general:\n",
    "  log_level: INFO\n",
    "generate:\n",
    "  chunk_word_count: 1000\n",
    "  model: granite-7b-lab-Q4_K_M\n",
    "  num_cpus: 10\n",
    "  num_instructions: 100\n",
    "  output_dir: generated\n",
    "  prompt_file: prompt.txt\n",
    "  seed_file: seed_tasks.json\n",
    "  taxonomy_base: origin/main\n",
    "  taxonomy_path: taxonomy\n",
    "serve:\n",
    "  gpu_layers: -1\n",
    "  host_port: 127.0.0.1:8000\n",
    "  max_ctx_size: 4096\n",
    "  model_path: models/granite-7b-lab-Q4_K_M.gguf\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35f1eb6-9091-4caf-9ba6-ec107d0a0dc5",
   "metadata": {},
   "source": [
    "Open 3 terminals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631f1ed3-ff14-4200-b5a9-e660151d959a",
   "metadata": {},
   "source": [
    "  (1) In the first we will run `ilab serve` to serve the model\n",
    "\n",
    "```bash\n",
    "(app-root) ilab serve\n",
    "INFO 2024-05-12 01:56:50,024 lab.py:313 Using model 'models/granite-7b-lab-Q4_K_M.gguf' with -1 gpu-layers and 4096 max context size.\n",
    "INFO 2024-05-12 01:56:51,387 server.py:196 Starting server process, press CTRL+C to shutdown server...\n",
    "INFO 2024-05-12 01:56:51,387 server.py:197 After application startup complete see http://127.0.0.1:8000/docs for API.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d307a155-a222-4f93-9000-98aa7fe2bcd2",
   "metadata": {},
   "source": [
    "  (2) In the second we will run `nvtop` utility built into the ilab image.\n",
    "\n",
    "```bash\n",
    "(app-root) nvtop\n",
    "```\n",
    "\n",
    "![ilab-nvtop.png](images/ilab-nvtop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3706541e-29bd-49ee-adc9-71ac11395d2e",
   "metadata": {},
   "source": [
    "  (3) In the third we rill run `ilab chat` to chat to the model interactively.\n",
    "    \n",
    "```bash\n",
    "(app-root) (app-root) ilab chat\n",
    "╭──────────────────────────────────────────────────────────────────────────────── system ────────────────╮\n",
    "│ Welcome to InstructLab Chat w/ GRANITE-7B-LAB-Q4_K_M (type /h for help)                                |\n",
    "╰────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
    ">>>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9e57ed-a367-4bb7-9cf9-7b4c0841da73",
   "metadata": {},
   "source": [
    "I am going to ask it about where i live a place called Kenmore Hills in Brisbane, Queensland, Australia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6707984c-8598-43a0-bd0b-ac0976e0a0e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "```bash\n",
    ">>> is kenmore hills in sydney ?                                                                   [S][default]\n",
    "╭────────────────────────────────────────── granite-7b-lab-Q4_K_M ───────────────────────────────────────────╮\n",
    "│ Kenmore Hills is not a separate suburb or neighborhood within Sydney, Australia. Instead, it is an         │\n",
    "│ affluent suburb located within the City of Bayside, on the eastern fringe of the city. To reach Kenmore    │\n",
    "│ Hills, you can take the Eastern Freeway (Eastlink) or the M5 East, and then exit at the Kenmore Terrace    │\n",
    "│ exit. The suburb is well-connected to public transportation, with several bus routes serving the area. If  │\n",
    "│ you have any questions about Kenmore Hills or other parts of Sydney, feel free to ask!                     │\n",
    "╰──────────────────────────────────────────────────────────────────────────────────── elapsed 3.012 seconds ─╯\n",
    ">>> where is knemore hills ?                                                                      [S][default]\n",
    "╭────────────────────────────────────────── granite-7b-lab-Q4_K_M ───────────────────────────────────────────╮\n",
    "│ Kenmore Hills is located on the eastern fringe of Sydney, within the City of Bayside. It is situated near  │\n",
    "│ the Parramatta River, approximately 10 kilometers (6 miles) east of the Sydney central business district.  │\n",
    "│ The suburb is surrounded by other well-known Sydney suburbs, including Hunters Hill, Wentworthville, and   │\n",
    "│ Strathfield South. If you need more specific directions or information about Kenmore Hills or its          │\n",
    "│ surroundings, please let me know!                                                                          │\n",
    "╰──────────────────────────────────────────────────────────────────────────────────── elapsed 2.605 seconds ─╯\n",
    ">>>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c957c0b-07dc-4173-bc39-4872a66b4667",
   "metadata": {},
   "source": [
    "Oh dear .. clearly the model does not know much about Kemore Hills. We are going to add knowledge into our own knowledge base and retrain the model so it can give better answers. You can read about how to do this [with taxonmies here](https://github.com/instructlab/taxonomy) - its as simple as creating a couple of text files in a git repo.\n",
    "\n",
    "For now, you can use my repo as an example (it has some other knowledge graph examples in there as well, but for now we will focus on Kenmore Hills)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1a814aa-b232-4b72-83b0-bb6172ffa6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/opt/app-root/src/instructlab/my_knowledge'...\n",
      "remote: Enumerating objects: 54, done.\u001b[K\n",
      "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
      "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
      "remote: Total 54 (delta 7), reused 52 (delta 5), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (54/54), 7.33 KiB | 7.33 MiB/s, done.\n",
      "Resolving deltas: 100% (7/7), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/eformat/my_knowledge.git $HOME/instructlab/my_knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d53b7c-b785-4421-8049-3d93b6e1d5dc",
   "metadata": {},
   "source": [
    "Exit from the chat and serve terminals (CTRL-c and CTRL-d) and take a look at the knowledge file for Kenmore Hills. I have created some question/answer pairs and formatted it according to the [taxnonomy](https://github.com/instructlab/taxonomy) instructions from instructlab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39f10f65-130e-4023-907d-4cfe8f9a484d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_description: \"Teach the model about Kenmore Hills\"\n",
      "domain: geography\n",
      "created_by: eformat\n",
      "seed_examples:\n",
      "  - question: Where is Kenmore Hills?\n",
      "    answer: |\n",
      "      Kenmore Hills is a suburb in the City of Brisbane, Queensland, Australia. In the 2016 census, Kenmore Hills had a population of 2,402 people.\n",
      "  - question: Who lives in Kenmore Hills?\n",
      "    answer: |\n",
      "      In the 2011 census, Kenmore Hills had a population of 2,577 people, 53.2% female and 46.8% male. The median age of the Kenmore Hills population was 44 years of age, 7 years above the Australian median. 60.5% of people living in Kenmore Hills were born in Australia, compared to the national average of 69.8%; the next most common countries of birth were England 7.5%, South Africa 4.2%, New Zealand 3%, India 2.4%, Scotland 1.3%. 81.3% of people spoke only English at home; the next most common languages were 1.9% Mandarin, 1.1% German, 1% Cantonese, 0.9% Telugu, 0.8% Afrikaans.\n",
      "  - question: What schools are in Kenmore Hills?\n",
      "    answer: |\n",
      "      There are no schools in Kenmore Hills. The nearest primary schools are Chapel Hill State School in neighbouring Chapel Hill to the east, Kenmore State School in neighbouring Kenmore to the south, and Brookfield State School in neighbouring Brookfield to the west. The nearest secondary school is Kenmore State High School in Kenmore.\n",
      "  - question: What Indigenous tribes lived in Kenmore Hills?\n",
      "    answer: |\n",
      "      The Indigenous people of the broad area are the Jagera and Turbal groups.\n",
      "  - question: Where is Kenmore Hills situated?\n",
      "    answer: |\n",
      "      Situated on the foothills of Mount Coot-tha, in Birsbane, Queensland - Kenmore Hills was a timber-cutting area in the 1860s. It was named after Kenmore (for awhile the administrative centre of Moggill Shire), which was named after an 1880s farm property, Kenmore Park.\n",
      "  - question: When was the Kenmore Hills Shopping center built?\n",
      "    answer: |\n",
      "      Urban facilities arrived in Kenmore, near the boundary with Kenmore Hills, with Kenmore Christian College (1964), Kenmore High school (1972) and Kenmore village shopping centre (1969).\n",
      "  - question: Does kenmore Hills have parks?\n",
      "    answer: |\n",
      "      Yes. Most of Kenmore Hills is rural/residential, the more developed part lying south of Brookfield Road. There are eight parks in Kenmore Hills with liner parks along the Gap and Moggill Creeks. The Tuckett Street Park has a cricket facility (Chadston Close), playground, water (bubbler/tap), seat\n",
      "document:\n",
      "  repo: https://github.com/eformat/my_knowledge.git\n",
      "  commit: b2b31f07c3a899347bdd0bd7c22593075e6ca288\n",
      "  patterns: \n",
      "    - \"*.md\"\n"
     ]
    }
   ],
   "source": [
    "!cat $HOME/instructlab/my_knowledge/geography/locations/brisbane/qna.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b28c70-23df-4f14-8f01-2ba8cc8fb36f",
   "metadata": {},
   "source": [
    "OK .. so the first step is to check the tamonomy structure is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff82dba0-1f71-4c68-b618-8b48559650c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mTaxonomy in /taxonomy/ is valid :)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd $HOME/instructlab && ilab diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518fdc9c-429e-4389-bc4a-c808008f9ccd",
   "metadata": {},
   "source": [
    "Good. we need to copy this into the real folder structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b68fd28-5639-4044-9840-94c3fa84b025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -Ra $HOME/instructlab/my_knowledge/* $HOME/instructlab/taxonomy/knowledge/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357066c9-b45b-4d05-8c41-7e8b2aa489d9",
   "metadata": {},
   "source": [
    "Now we need to create some synthetic Q&A to train the model with based on this knowledge. Ideally you should verify the output for valid answers and adjust as desired. The default is 100, let's up this a little bit. This is a time and GPU intensive task as it uses the LLM model to generate the synthetic Q&A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c998fce-6045-48ae-a426-bd57d1fbafd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd $HOME/instructlab && time ilab generate --num-instructions 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3879c15b-5dcd-4f2b-8ac6-cd9967b3a414",
   "metadata": {},
   "source": [
    "I have cleared the output from the generate cell - as it is long.. but it should look like this:\n",
    "\n",
    "```bash\n",
    "Generating synthetic data using 'granite-7b-lab-Q4_K_M' model, taxonomy:'taxonomy' against http://127.0.0.1:57250/v1 server\n",
    "INFO 2024-05-12 02:19:31,007 rouge_scorer.py:83 Using default tokenizer.\n",
    "  0%|                                                   | 0/200 [00:00<?, ?it/s]Cannot find prompt.txt. Using default prompt depending on model-family.\n",
    "Synthesizing new instructions. If you aren't satisfied with the generated instructions, interrupt training (Ctrl-C) and try adjusting your YAML files. Adding more examples may help.\n",
    "INFO 2024-05-12 02:19:31,009 generate_data.py:468 Selected taxonomy path knowledge->tech_industry->redhat\n",
    "...\n",
    "\n",
    " 99%|████████████████████████████████████████▌| 198/200 [26:12<00:15,  7.92s/it]INFO 2024-05-12 02:45:43,588 generate_data.py:468 Selected taxonomy path knowledge->tech_industry->redhat\n",
    "INFO 2024-05-12 02:45:54,027 generate_data.py:468 Selected taxonomy path knowledge->geography->locations->brisbane\n",
    "Q> How many kilometers is Kenmore Hills from the Brisbane Airport?\n",
    "I> <no input>\n",
    "A> Kenmore Hills is approximately 14 kilometers from the Brisbane Airport, which takes about 25-30 minutes to drive, depending on traffic and the route taken.\n",
    "\n",
    "100%|████████████████████████████████████████▊| 199/200 [26:31<00:10, 10.23s/it]INFO 2024-05-12 02:46:02,058 generate_data.py:468 Selected taxonomy path knowledge->sports->rubgy\n",
    "Q> What is the current Rugby World Cup standings?\n",
    "I> \n",
    "A> The current Rugby World Cup standings are: 1. England, 2. South Africa, 3. New Zealand, 4. Ireland, 5. France\n",
    "\n",
    "100%|█████████████████████████████████████████| 200/200 [26:55<00:00, 13.55s/it]INFO 2024-05-12 02:46:26,238 generate_data.py:562 200 instructions generated, 48 discarded due to format (see generated/discarded_granite-7b-lab-Q4_K_M_2024-05-12T02_19_31.log), 63 discarded due to rouge score\n",
    "INFO 2024-05-12 02:46:26,238 generate_data.py:566 Generation took 1616.17s\n",
    "100%|█████████████████████████████████████████| 200/200 [26:55<00:00,  8.08s/it]\n",
    "\n",
    "real\t27m2.519s\n",
    "user\t69m1.862s\n",
    "sys\t22m21.813s\n",
    "```\n",
    "\n",
    "and you can see using `nvtop` the GPU is busy.\n",
    "\n",
    "![ilab-nvtop-generate.png](images/ilab-nvtop-generate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce9942-6b3c-4829-92dd-e26ac3d29136",
   "metadata": {},
   "source": [
    "This creates a `generated` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3569e001-e06f-494a-86e6-c5b07cf4ff6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discarded_granite-7b-lab-Q4_K_M_2024-05-12T02_19_31.log\n",
      "generated_granite-7b-lab-Q4_K_M_2024-05-12T02_19_31.json\n",
      "test_granite-7b-lab-Q4_K_M_2024-05-12T02_19_31.jsonl\n",
      "train_granite-7b-lab-Q4_K_M_2024-05-12T02_19_31.jsonl\n"
     ]
    }
   ],
   "source": [
    "!ls $HOME/instructlab/generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab69bb3-1e7d-41c6-87c0-fcb6428f0f2b",
   "metadata": {},
   "source": [
    "We can now train our model. The training step downloads and caches the original model from huggingface (up till now we are using the quantized version of the model). We give it the model name [as it appears on huggingface](https://huggingface.co/instructlab/granite-7b-lab). You can check it downloads and caches to here `ls ~/.cache/huggingface/hub/`. We also bump up the iterations from the default 100.\n",
    "\n",
    "If this command causes your ipython terminal to OOM, you can `oc rsh jupyter-nb-admin-0` to the notebook pod and run it from the CLI - this should work OK with the memory settings of `small` when you started the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8245dca-8d97-464d-99da-5df72f184665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd $HOME/instructlab && time ilab train --device=cuda --model-name instructlab/granite-7b-lab --iters 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b8705d-8aef-4f7b-ab87-d3963cbe8759",
   "metadata": {},
   "source": [
    "The output should look like this (abbreviated)\n",
    "\n",
    "```bash\n",
    "$ oc rsh jupyter-nb-admin-0\n",
    "Defaulted container \"jupyter-nb-admin\" out of: jupyter-nb-admin, oauth-proxy\n",
    "(app-root) sh-5.1$ cd instructlab/\n",
    "(app-root) sh-5.1$ time ilab train --device=cuda --model-name instructlab/granite-7b-lab --iters 200\n",
    "INFO 2024-05-12 05:37:35,876 config.py:58 PyTorch version 2.3.0 available.\n",
    "LINUX_TRAIN.PY: NUM EPOCHS IS:  1\n",
    "LINUX_TRAIN.PY: TRAIN FILE IS:  generated/train_granite-7b-lab-Q4_K_M_2024-05-12T02_19_31.jsonl\n",
    "LINUX_TRAIN.PY: TEST FILE IS:  generated/test_granite-7b-lab-Q4_K_M_2024-05-12T02_19_31.jsonl\n",
    "LINUX_TRAIN.PY: Using device 'cuda:0'\n",
    "  NVidia CUDA version: 12.1\n",
    "  AMD ROCm HIP version: n/a\n",
    "  cuda:0 is 'NVIDIA L4' (21.8 GiB of 22.0 GiB free, capability: 8.9)\n",
    "LINUX_TRAIN.PY: LOADING DATASETS\n",
    "/opt/app-root/lib64/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
    "  warnings.warn(\n",
    "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
    "LINUX_TRAIN.PY: NOT USING 4-bit quantization\n",
    "LINUX_TRAIN.PY: LOADING THE BASE MODEL\n",
    "Loading checkpoint shards: 100%|████████████████████████████████████████████████| 3/3 [00:09<00:00,  3.07s/it]\n",
    "LINUX_TRAIN.PY: Model device cuda:0\n",
    "|===========================================================================|\n",
    "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
    "|---------------------------------------------------------------------------|\n",
    "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
    "|===========================================================================|\n",
    "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
    "|---------------------------------------------------------------------------|\n",
    "| Allocated memory      |  12888 MiB |  12888 MiB |  12888 MiB |      0 B   |\n",
    "|       from large pool |  12856 MiB |  12856 MiB |  12856 MiB |      0 B   |\n",
    "|       from small pool |     32 MiB |     32 MiB |     32 MiB |      0 B   |\n",
    "|---------------------------------------------------------------------------|\n",
    "| Active memory         |  12888 MiB |  12888 MiB |  12888 MiB |      0 B   |\n",
    "|       from large pool |  12856 MiB |  12856 MiB |  12856 MiB |      0 B   |\n",
    "|       from small pool |     32 MiB |     32 MiB |     32 MiB |      0 B   |\n",
    "|---------------------------------------------------------------------------|\n",
    "| Requested memory      |  12888 MiB |  12888 MiB |  12888 MiB |      0 B   |\n",
    "|       from large pool |  12856 MiB |  12856 MiB |  12856 MiB |      0 B   |\n",
    "|       from small pool |     32 MiB |     32 MiB |     32 MiB |      0 B   |\n",
    "|---------------------------------------------------------------------------|\n",
    "| GPU reserved memory   |  12910 MiB |  12910 MiB |  12910 MiB |      0 B   |\n",
    "|       from large pool |  12876 MiB |  12876 MiB |  12876 MiB |      0 B   |\n",
    "|       from small pool |     34 MiB |     34 MiB |     34 MiB |      0 B   |\n",
    "|---------------------------------------------------------------------------|\n",
    "| Non-releasable memory |  21864 KiB |  21864 KiB |  46975 KiB |  25111 KiB |\n",
    "|       from large pool |  20352 KiB |  20352 KiB |  20352 KiB |      0 KiB |\n",
    "|       from small pool |   1512 KiB |   2047 KiB |  26623 KiB |  25111 KiB |\n",
    "|---------------------------------------------------------------------------|\n",
    "| Allocations           |     388    |     388    |     388    |       0    |\n",
    "|       from large pool |     227    |     227    |     227    |       0    |\n",
    "|       from small pool |     161    |     161    |     161    |       0    |\n",
    "|---------------------------------------------------------------------------|\n",
    "| Active allocs         |     388    |     388    |     388    |       0    |\n",
    "|       from large pool |     227    |     227    |     227    |       0    |\n",
    "|       from small pool |     161    |     161    |     161    |       0    |\n",
    "|---------------------------------------------------------------------------|\n",
    "| GPU reserved segments |     244    |     244    |     244    |       0    |\n",
    "|       from large pool |     227    |     227    |     227    |       0    |\n",
    "|       from small pool |      17    |      17    |      17    |       0    |\n",
    "|---------------------------------------------------------------------------|\n",
    "| Non-releasable allocs |       4    |       4    |      20    |      16    |\n",
    "|       from large pool |       3    |       3    |       3    |       0    |\n",
    "|       from small pool |       1    |       2    |      17    |      16    |\n",
    "|---------------------------------------------------------------------------|\n",
    "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
    "|---------------------------------------------------------------------------|\n",
    "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
    "|===========================================================================|\n",
    "\n",
    "LINUX_TRAIN.PY: SANITY CHECKING THE BASE MODEL\n",
    "LINUX_TRAIN.PY: GETTING THE ATTENTION LAYERS\n",
    "LINUX_TRAIN.PY: CONFIGURING LoRA\n",
    "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
    "To disable this warning, you can either:\n",
    "\t- Avoid using `tokenizers` before the fork if possible\n",
    "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
    "/opt/app-root/lib64/python3.9/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
    "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
    "  warnings.warn(\n",
    "LINUX_TRAIN.PY: TRAINING\n",
    "100%|███████████████████████████████████████████████████████████████████████| 200/200 [00:42<00:00,  4.48it/s]Checkpoint destination directory ./training_results/checkpoint-200 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
    "/opt/app-root/lib64/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
    "  warnings.warn(\n",
    "{'train_runtime': 42.557, 'train_samples_per_second': 4.7, 'train_steps_per_second': 4.7, 'train_loss': 0.6415711975097657, 'epoch': 1.0}\n",
    "100%|███████████████████████████████████████████████████████████████████████| 200/200 [00:42<00:00,  4.70it/s]\n",
    "LINUX_TRAIN.PY: RUNNING INFERENCE ON THE OUTPUT MODEL\n",
    "\n",
    "===\n",
    "test 0\n",
    "===\n",
    "\n",
    "\n",
    "===\n",
    "user\n",
    "===\n",
    "\n",
    "Where is Kenmore Hills?\n",
    "\n",
    "===\n",
    "assistant_old\n",
    "===\n",
    "\n",
    "Kenmore Hills is a residential neighborhood located in the southwestern part of Perth, the capital city of Western Australia. It is situated approximately 10 kilometers (6.2 miles) south of Perth's central business district, and is bordered by several major roads, including Leach Highway, Reid Highway, and the South Western Highway.\n",
    "\n",
    "Kenmore Hills is a relatively new suburb, with most of its development taking place in the late 20th century. It is known for its picturesque parklands, including Kenmore Park, and offers a range of housing options, from low-rise apartments to large family homes. The suburb is also home to several schools, shops, and recreational facilities, making it a popular choice for families and professionals alike.\n",
    "\n",
    "If you're planning a visit to Kenmore Hills, you'll find it easy to access the suburb from various parts of Perth. The Freeway, a major highway in Western Australia, provides easy access to the suburb from the city and other major destinations. Additionally, there are several bus services that run through Kenmore Hills, connecting it to the wider Perth metropolitan area\n",
    "\n",
    "===\n",
    "assistant_new\n",
    "===\n",
    "\n",
    "Kenmore Hills is a suburb located in the Brisbane district of Queensland, Australia. It is situated approximately 7 kilometers west of the Brisbane CBD, offering a convenient location for residents to access city amenities while still enjoying a more suburban lifestyle. The suburb is well-connected by public transportation, with several bus routes serving the area and the nearby Kenmore railway station providing easy access to other parts of Brisbane. Kenmore Hills boasts a variety of housing options, ranging from family homes to apartments, making it an attractive choice for people of all ages and stages of life. The suburb also features several parks, reserves, and recreational facilities, ensuring there's always something to do or explore. If you have any specific questions about Kenmore Hills or its surrounding areas, please let me know, and I'd be happy to help!\n",
    "\n",
    "===\n",
    "assistant_expected\n",
    "===\n",
    "\n",
    "Kenmore Hills is a suburb in the City of Brisbane, Queensland, Australia. In the 2016 census, Kenmore Hills had a population of 2,402 people.\n",
    "\n",
    "...\n",
    "\n",
    "LINUX_TRAIN.PY: MERGING ADAPTERS\n",
    "LINUX_TRAIN.PY: FINISHED\n",
    "Copied  ./training_results/checkpoint-200/added_tokens.json to  ./training_results/final\n",
    "Copied  ./training_results/checkpoint-200/special_tokens_map.json to  ./training_results/final\n",
    "Copied  ./training_results/checkpoint-200/tokenizer.json to  ./training_results/final\n",
    "Copied  ./training_results/checkpoint-200/tokenizer.model to  ./training_results/final\n",
    "Copied  ./training_results/checkpoint-200/tokenizer_config.json to  ./training_results/final\n",
    "Copied  ./training_results/merged_model/config.json to  ./training_results/final\n",
    "Copied  ./training_results/merged_model/generation_config.json to  ./training_results/final\n",
    "Copied  ./training_results/merged_model/model-00001-of-00003.safetensors to  ./training_results/final\n",
    "Copied  ./training_results/merged_model/model-00002-of-00003.safetensors to  ./training_results/final\n",
    "Copied  ./training_results/merged_model/model-00003-of-00003.safetensors to  ./training_results/final\n",
    "Loading model file training_results/final/model-00001-of-00003.safetensors\n",
    "Loading model file training_results/final/model-00001-of-00003.safetensors\n",
    "Loading model file training_results/final/model-00002-of-00003.safetensors\n",
    "Loading model file training_results/final/model-00003-of-00003.safetensors\n",
    "params = Params(n_vocab=32008, n_embd=4096, n_layer=32, n_ctx=2048, n_ff=11008, n_head=32, n_head_kv=32, n_experts=None, n_experts_used=None, f_norm_eps=1e-05, rope_scaling_type=None, f_rope_freq_base=10000.0, f_rope_scale=None, n_orig_ctx=None, rope_finetuned=None, ftype=None, path_model=PosixPath('training_results/final'))\n",
    "Found vocab files: {'spm': PosixPath('training_results/final/tokenizer.model'), 'bpe': None, 'hfft': PosixPath('training_results/final/tokenizer.json')}\n",
    "Loading vocab file PosixPath('training_results/final/tokenizer.model'), type 'spm'\n",
    "Vocab info: <SentencePieceVocab with 32000 base tokens and 5 added tokens>\n",
    "Special vocab info: <SpecialVocab with 0 merges, special tokens {'bos': 1, 'eos': 32000, 'unk': 0, 'pad': 32000}, add special tokens {'bos': False, 'eos': False}>\n",
    "Permuting layer 0\n",
    "Permuting layer 1\n",
    "...\n",
    "Permuting layer 30\n",
    "Permuting layer 31\n",
    "model.embed_tokens.weight                        -> token_embd.weight                        | BF16   | [32008, 4096]\n",
    "model.layers.0.input_layernorm.weight            -> blk.0.attn_norm.weight                   | BF16   | [4096]\n",
    "model.layers.0.mlp.down_proj.weight              -> blk.0.ffn_down.weight                    | BF16   | [4096, 11008]\n",
    "model.layers.0.mlp.gate_proj.weight              -> blk.0.ffn_gate.weight                    | BF16   | [11008, 4096]\n",
    "model.layers.0.mlp.up_proj.weight                -> blk.0.ffn_up.weight                      | BF16   | [11008, 4096]\n",
    "model.layers.0.post_attention_layernorm.weight   -> blk.0.ffn_norm.weight                    | BF16   | [4096]\n",
    "model.layers.0.self_attn.k_proj.weight           -> blk.0.attn_k.weight                      | BF16   | [4096, 4096]\n",
    "model.layers.0.self_attn.o_proj.weight           -> blk.0.attn_output.weight                 | BF16   | [4096, 4096]\n",
    "model.layers.0.self_attn.q_proj.weight           -> blk.0.attn_q.weight                      | BF16   | [4096, 4096]\n",
    "model.layers.0.self_attn.v_proj.weight           -> blk.0.attn_v.weight                      | BF16   | [4096, 4096]\n",
    "model.layers.1.input_layernorm.weight            -> blk.1.attn_norm.weight                   | BF16   | [4096]\n",
    "...\n",
    "\n",
    "Writing training_results/final/ggml-model-f16.gguf, format 1\n",
    "Padding vocab with 3 token(s) - <dummy00001> through <dummy00003>\n",
    "gguf: This GGUF file is for Little Endian only\n",
    "gguf: Setting special token type bos to 1\n",
    "gguf: Setting special token type eos to 32000\n",
    "gguf: Setting special token type unk to 0\n",
    "gguf: Setting special token type pad to 32000\n",
    "gguf: Setting add_bos_token to False\n",
    "gguf: Setting add_eos_token to False\n",
    "gguf: Setting chat_template to {% for message in messages %}{% if message['role'] == 'system' %}{{'<|system|>'+ '\n",
    "' + message['content'] + '\n",
    "'}}{% elif message['role'] == 'user' %}{{'<|user|>' + '\n",
    "' + message['content'] + '\n",
    "'}}{% elif message['role'] == 'assistant' %}{{'<|assistant|>' + '\n",
    "' + message['content'] + '<|endoftext|>' + ('' if loop.last else '\n",
    "')}}{% endif %}{% endfor %}\n",
    "[  1/291] Writing tensor token_embd.weight                      | size  32008 x   4096  | type F16  | T+   1\n",
    "[  2/291] Writing tensor blk.0.attn_norm.weight                 | size   4096           | type F32  | T+   1\n",
    "...\n",
    "\n",
    "[291/291] Writing tensor output_norm.weight                     | size   4096           | type F32  | T+ 127\n",
    "Wrote training_results/final/ggml-model-f16.gguf\n",
    "\n",
    "real\t15m2.636s\n",
    "user\t7m44.474s\n",
    "sys\t1m10.844s\n",
    "(app-root) sh-5.1$ \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd3d4ad-cb54-49e2-9516-6ca5477c0770",
   "metadata": {},
   "source": [
    "Now we are good to try out our serve and chat again on the new model. Let's see if it does any better on the subject of Kenmore Hills !\n",
    "\n",
    "The new model will be saved under the `models/` folder.\n",
    "\n",
    "(1) serve the model\n",
    "\n",
    "ilab serve --model-path $HOME/instructlab/models/ggml-model-f16.gguf\n",
    "\n",
    "(2) chat with the new model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423bdb9b-235e-437c-a57d-f6af7e615a9f",
   "metadata": {},
   "source": [
    "```bash\n",
    "(app-root) (app-root) ilab chat\n",
    "╭────────────────────────────────────────────────── system ───────────────────────────────────────────────────╮\n",
    "│ Welcome to InstructLab Chat w/ GRANITE-7B-LAB-Q4_K_M (type /h for help)                                     │\n",
    "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
    ">>> is kenmore hills in sydney ?                                                                                                                              [S][default]\n",
    "╭────────────────────────────────────────────────── granite-7b-lab-Q4_K_M ────────────────────────────────────╮\n",
    "│ Yes, Kenmore Hills is indeed located in the city of Brisbane, which is the capital city of the Australian   |\n",
    "| state of Queensland, not Sydney. Brisbane is approximately 725 kilometers (450 miles) north of Sydney, so it|\n",
    "| is not located in Sydney. Kenmore Hills is a suburb of Brisbane, known for its picturesque views of the city|\n",
    "| skyline and the Brisbane River. It is a popular residential area with a growing population, offering        |\n",
    "| convenient access to various amenities, including schools, parks, shopping centers, and public              |\n",
    "| transportation.                                                                                             │\n",
    "╰───────────────────────────────────────────────────────────────────────────────────── elapsed 7.687 seconds ─╯\n",
    ">>> where is kenmore hills ?                                                                                                                                  [S][default]\n",
    "╭────────────────────────────────────────────────── granite-7b-lab-Q4_K_M ────────────────────────────────────╮\n",
    "│ Kenmore Hills is a suburb of Brisbane, Queensland, Australia, situated in the City of Brisbane local        |\n",
    "| government area. It is approximately 12 kilometers (7.5 miles) west of the Brisbane CBD (Central Business   |\n",
    "| District) and is well-connected to various parts of the city through the Western Freeway and the Logan      |\n",
    "| Motorway. The suburb is nestled among the Brisbane Ranges, offering picturesque views of the city skyline   |\n",
    "| and the Brisbane River. Kenmore Hills boasts several parks, reserves, and schools, making it an attractive  |\n",
    "| location for families and professionals alike.                                                              │\n",
    "╰───────────────────────────────────────────────────────────────────────────────────── elapsed 8.644 seconds ─╯\n",
    ">>>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a93b451-fb71-4f57-8281-f30972da4ef4",
   "metadata": {
    "tags": []
   },
   "source": [
    "🥳🥳🥳 WHOOP, success - the model appeats to have learnt a little more about Kenmore Hills !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e49aa-48c0-44f4-b1c3-04eb33506184",
   "metadata": {},
   "outputs": [],
   "source": [
    "🦩 initial commit 🦩"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
